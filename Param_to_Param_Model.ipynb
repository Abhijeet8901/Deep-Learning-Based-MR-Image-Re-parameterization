{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Param-to-Param Model",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xZD7ASZbnRmg3cP74QK3ac9wDbz5UwSq",
      "authorship_tag": "ABX9TyOllDNfAF+rbXWBy24RFbIc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZkzYWnvKk2T"
      },
      "source": [
        "#Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqs91zoXKFrh"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import os\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import random\n",
        " \n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
        "from skimage.io import imsave\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from torchsummary import summary\n",
        " \n",
        "from itertools import product\n",
        "from math import log10, sqrt\n",
        " \n",
        "dtype = torch.cuda.FloatTensor\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available()==False:\n",
        "  dtype=torch.FloatTensor\n",
        "print(device,dtype) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHXec2tjK-co"
      },
      "source": [
        "#Set Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-zmIhvnLDI1"
      },
      "source": [
        "class set_config:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.cuda=torch.cuda.is_available()\n",
        "    self.weight_decay=0 \n",
        "    self.lr=1e-3 # learning rate\n",
        "    self.test_img_name=None \n",
        "    self.batch_size=8 \n",
        "    self.mode='train'  # 3 modes, 'train', 'test', 'detect'\n",
        "    self.resume=False # if resume is set to true, resumes training from pretrained weights.\n",
        "    self.dir='drive/MyDrive/Projects/K-Parameter/' # path to root directory\n",
        "    self.param_weight_path=glob.glob(self.dir+'weights/latest_KParameter*')  # path to param-net model weights\n",
        "    assert len(self.param_weight_path)<=1, \"Multiple Param weight files detected.\"\n",
        "    if len(self.param_weight_path)==1:\n",
        "      self.resume=True\n",
        "      self.param_weight_path=self.param_weight_path[0]\n",
        "    else:\n",
        "      self.param_weight_path=None\n",
        "    self.end_weight_path=glob.glob(self.dir+'weights/latest_END*') # path to end(autoencoder) model weights\n",
        "    assert len(self.end_weight_path)<=1, \"Multiple END weight files detected.\"\n",
        "    if len(self.end_weight_path)==1:\n",
        "      self.end_weight_path=self.end_weight_path[0]\n",
        "    else:\n",
        "      self.end_weight_path=None\n",
        "    self.train_file_name=\"Train_1500\" # folder name in 'dataset/' folder to training images\n",
        "    self.test_file_name=\"brainweb images\" # folder name in 'dataset/' folder to training images\n",
        "\n",
        "config=set_config()\n",
        "if config.param_weight_path is not None:\n",
        "  print(\"Param Weight file detected.\",config.param_weight_path)\n",
        "else:\n",
        "  print(\"No Param weight file detected.\")\n",
        "if config.end_weight_path is not None:\n",
        "  print(\"END Weight file detected.\",config.end_weight_path)\n",
        "else:\n",
        "  print(\"No END weight file detected.\")\n",
        "  #assert False, \"No END weight file detected.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0EW0ZhjLIZt"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1izT1tdLIHF"
      },
      "source": [
        "class END(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv2d(1,64,3,stride=1,padding=1,bias=False)\n",
        "    self.relu1=nn.LeakyReLU(0.2)\n",
        "\n",
        "    self.conv2=nn.Conv2d(64,64,3,stride=2,padding=1,bias=False)\n",
        "    self.bn2=nn.BatchNorm2d(64,momentum=0.5)\n",
        "    self.relu2=nn.LeakyReLU(0.2)\n",
        "\n",
        "    self.conv3=nn.Conv2d(64,128,3,stride=2,padding=1,bias=False)\n",
        "    self.bn3=nn.BatchNorm2d(128,momentum=0.5)\n",
        "    self.relu3=nn.LeakyReLU(0.2)\n",
        "\n",
        "    self.conv4=nn.Conv2d(128,256,3,stride=2,padding=1,bias=False)\n",
        "    self.bn4=nn.BatchNorm2d(256,momentum=0.5)\n",
        "    self.relu4=nn.LeakyReLU(0.2)\n",
        "\n",
        "    self.conv5=nn.Conv2d(256,512,3,stride=2,padding=1,bias=False)\n",
        "    self.bn5=nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.relu5=nn.LeakyReLU(0.2)\n",
        "\n",
        "    self.conv6=nn.Conv2d(512,512,3,stride=2,padding=1,bias=False)\n",
        "    self.bn6=nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.relu6=nn.LeakyReLU(0.2)\n",
        "\n",
        "    self.conv7=nn.Conv2d(512,512,3,stride=2,padding=1,bias=False)\n",
        "    self.bn7=nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.relu7=nn.LeakyReLU(0.2)\n",
        "\n",
        "    self.conv8=nn.Conv2d(512,512,3,stride=2,padding=1,bias=False)\n",
        "    self.bn8=nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.relu8=nn.LeakyReLU(0.2)\n",
        "\n",
        "    self.conv9=nn.ConvTranspose2d(512,512,3,stride=2,padding=1,output_padding=1,bias=False)\n",
        "    self.bn9=nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.relu9=nn.ReLU()\n",
        "      \n",
        "    self.conv10=nn.ConvTranspose2d(512,512,3,stride=2,padding=1,output_padding=1,bias=False)\n",
        "    self.bn10=nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.relu10=nn.ReLU()\n",
        "\n",
        "    self.conv11=nn.ConvTranspose2d(512,512,3,stride=2,padding=1,output_padding=1,bias=False)\n",
        "    self.bn11=nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.relu11=nn.ReLU()\n",
        "\n",
        "    self.conv12=nn.ConvTranspose2d(512,256,3,stride=2,padding=1,output_padding=1,bias=False)\n",
        "    self.bn12=nn.BatchNorm2d(256,momentum=0.5)\n",
        "    self.relu12=nn.ReLU()\n",
        "\n",
        "    self.conv13=nn.ConvTranspose2d(256,128,3,stride=2,padding=1,output_padding=1,bias=False)\n",
        "    self.bn13=nn.BatchNorm2d(128,momentum=0.5)\n",
        "    self.relu13=nn.ReLU()\n",
        "\n",
        "    self.conv14=nn.ConvTranspose2d(128,64,3,stride=2,padding=1,output_padding=1,bias=False)\n",
        "    self.bn14=nn.BatchNorm2d(64,momentum=0.5)\n",
        "    self.relu14=nn.ReLU()\n",
        "\n",
        "    self.conv15=nn.ConvTranspose2d(64,32,3,stride=2,padding=1,output_padding=1,bias=False)\n",
        "    self.bn15=nn.BatchNorm2d(32,momentum=0.5)\n",
        "    self.relu15=nn.ReLU()\n",
        "      \n",
        "    self.conv16=nn.Conv2d(32,16,3,stride=1,padding=1,bias=False)\n",
        "    self.bn16=nn.BatchNorm2d(16,momentum=0.5)\n",
        "    self.relu16=nn.ReLU()\n",
        "\n",
        "    self.conv17=nn.Conv2d(16,1,1,stride=1,bias=False)\n",
        "\n",
        "  def forward(self,img):\n",
        "\n",
        "    if self.training:\n",
        "\n",
        "      x1=self.relu1(self.conv1(img))\n",
        "\n",
        "      x2=self.relu2(self.bn2(self.conv2(x1)))\n",
        "\n",
        "      x3=self.relu3(self.bn3(self.conv3(x2)))\n",
        "\n",
        "      x4=self.relu4(self.bn4(self.conv4(x3)))\n",
        "\n",
        "      x5=self.relu5(self.bn5(self.conv5(x4)))\n",
        "\n",
        "      x6=self.relu6(self.bn6(self.conv6(x5)))\n",
        "\n",
        "      x7=self.relu7(self.bn7(self.conv7(x6)))\n",
        "\n",
        "      x8=self.relu8(self.bn8(self.conv8(x7)))\n",
        "\n",
        "      x9=self.relu9(self.bn9(self.conv9(x8)))\n",
        "\n",
        "      x10=self.relu10(self.bn10(self.conv10(x9)))\n",
        "\n",
        "      x11=self.relu11(self.bn11(self.conv11(x10)))\n",
        "\n",
        "      x12=self.relu12(self.bn12(self.conv12(x11)))\n",
        "\n",
        "      x13=self.relu13(self.bn13(self.conv13(x12)))\n",
        "\n",
        "      x14=self.relu14(self.bn14(self.conv14(x13)))\n",
        "\n",
        "      x15=self.relu15(self.bn15(self.conv15(x14)))\n",
        "\n",
        "      x16=self.relu16(self.bn16(self.conv16(x15)))\n",
        "        \n",
        "      x17=self.conv17(x16)\n",
        "      x17=torch.tanh(x17)\n",
        "      \n",
        "      return x17\n",
        "    \n",
        "    else:\n",
        "\n",
        "      outs=[]\n",
        "\n",
        "      x1=self.relu1(self.conv1(img))\n",
        "      outs.append(x1)\n",
        "\n",
        "      x2=self.relu2(self.bn2(self.conv2(x1)))\n",
        "      outs.append(x2)\n",
        "\n",
        "      x3=self.relu3(self.bn3(self.conv3(x2)))\n",
        "      outs.append(x3)\n",
        "\n",
        "      x4=self.relu4(self.bn4(self.conv4(x3)))\n",
        "      outs.append(x4)\n",
        "\n",
        "      x5=self.relu5(self.bn5(self.conv5(x4)))\n",
        "      outs.append(x5)\n",
        "\n",
        "      x6=self.relu6(self.bn6(self.conv6(x5)))\n",
        "      outs.append(x6)\n",
        "\n",
        "      x7=self.relu7(self.bn7(self.conv7(x6)))\n",
        "      outs.append(x7)\n",
        "\n",
        "      x8=self.relu8(self.bn8(self.conv8(x7)))\n",
        "      outs.append(x8)\n",
        "\n",
        "      return outs\n",
        "  \n",
        "  def init_weights(self):\n",
        "    for name,module in self.named_modules():\n",
        "      if isinstance(module,nn.Conv2d) or isinstance(module,nn.ConvTranspose2d):\n",
        "        nn.init.xavier_uniform_(module.weight.data)\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaZYkMLyLLpn"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channels,out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=in_channels # no of channels of input\n",
        "    self.out_channels=out_channels # required no of channels of output\n",
        "    # as each block of param-net has different input and output size, therefore we had to generalize the no of input and output channels\n",
        "\n",
        "    self.conv_t=nn.ConvTranspose2d(in_channels,in_channels,3,stride=2,padding=1,output_padding=1,bias=False)  ##2x*2x*in_channels\n",
        "    self.conv1=nn.Conv2d(2*in_channels,in_channels,3,stride=1,padding=1,bias=False)                           ##2x*2x*in_channels\n",
        "    self.in1=nn.InstanceNorm2d(in_channels)\n",
        "    self.relu1=nn.LeakyReLU(0.2)\n",
        "    self.conv2=nn.Conv2d(2*in_channels,in_channels,3,stride=1,padding=1,bias=False)                           ##2x*2x*in_channels\n",
        "    self.in2=nn.InstanceNorm2d(in_channels)\n",
        "    self.relu2=nn.LeakyReLU(0.2)\n",
        "    self.conv3=nn.Conv2d(in_channels,out_channels,3,stride=1,padding=1,bias=False)                           ##2x*2x*out_channels\n",
        "    self.in3=nn.InstanceNorm2d(out_channels)\n",
        "    self.relu3=nn.LeakyReLU(0.2)\n",
        "\n",
        "  def forward(self,input,brain_features,params):\n",
        "\n",
        "    # brain features: image features from END model(autoencoder model)\n",
        "    # params : parameters of required output\n",
        "    \n",
        "    x1=self.conv_t(input)\n",
        "    x1=torch.cat([x1,brain_features],dim=1)\n",
        "\n",
        "    x2=self.conv1(x1)\n",
        "    x2=self.in1(x2)\n",
        "    x2=self.relu1(x2)\n",
        "    x2=torch.cat([x2,params[:,0:x2.shape[1],0:x2.shape[2],0:x2.shape[3]]],dim=1)\n",
        "\n",
        "    x3=self.conv2(x2)\n",
        "    x3=self.in2(x3)\n",
        "    x3=self.relu2(x3)\n",
        "\n",
        "    x4=self.conv3(x3)\n",
        "    x4=self.in3(x4)\n",
        "    x4=self.relu3(x4)\n",
        "\n",
        "    return x4\n",
        "  \n",
        "  def init_weights(self):\n",
        "    for name,module in self.named_modules():\n",
        "      if isinstance(module,nn.Conv2d) or isinstance(module,nn.ConvTranspose2d):\n",
        "        nn.init.xavier_uniform_(module.weight.data)\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfD6AstALPB-"
      },
      "source": [
        "class ParamNet(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.block1 = BasicBlock(in_channels=512,out_channels=512)          ## 2*2*512\n",
        "    self.block2 = BasicBlock(in_channels=512,out_channels=512)          ## 4*4*512\n",
        "    self.block3 = BasicBlock(in_channels=512,out_channels=512)          ## 8*8*512\n",
        "    self.block4 = BasicBlock(in_channels=512,out_channels=256)          ## 16*16*256\n",
        "    self.block5 = BasicBlock(in_channels=256,out_channels=128)          ## 32*32*128\n",
        "    self.block6 = BasicBlock(in_channels=128,out_channels=64)           ## 64*64*64\n",
        "    self.block7 = BasicBlock(in_channels=64,out_channels=64)            ## 128*128*64\n",
        "    self.block8 = BasicBlock(in_channels=64,out_channels=32)            ## 256*256*32\n",
        "    self.conv1 = nn.Conv2d(32,16,3,stride=1,padding=1,bias=False)       ## 256*256*16\n",
        "    self.in1=nn.InstanceNorm2d(16)\n",
        "    self.relu1=nn.LeakyReLU(0.2)\n",
        "    self.conv2 = nn.Conv2d(16,1,3,stride=1,padding=1,bias=False)        ## 256*256*1\n",
        "  \n",
        "  def forward(self,brain_features,params):\n",
        "    \n",
        "    input=params[:,0:512,0:1,0:1]\n",
        "    \n",
        "    out1=self.block1(input,brain_features.pop(-1),params)\n",
        "    \n",
        "    out2=self.block2(out1,brain_features.pop(-1),params)\n",
        "\n",
        "    out3=self.block3(out2,brain_features.pop(-1),params)\n",
        "\n",
        "    out4=self.block4(out3,brain_features.pop(-1),params)\n",
        "\n",
        "    out5=self.block5(out4,brain_features.pop(-1),params)\n",
        "\n",
        "    out6=self.block6(out5,brain_features.pop(-1),params)\n",
        "\n",
        "    out7=self.block7(out6,brain_features.pop(-1),params)\n",
        "\n",
        "    out8=self.block8(out7,brain_features.pop(-1),params)\n",
        "\n",
        "    out9=self.relu1(self.in1(self.conv1(out8)))\n",
        "\n",
        "    out10=self.conv2(out9)\n",
        "\n",
        "    ou10=torch.tanh(out10)\n",
        "\n",
        "    return out10\n",
        "    \n",
        "  def init_weights(self):\n",
        "    for name,module in self.named_modules():\n",
        "      if isinstance(module,nn.Conv2d) or isinstance(module,nn.ConvTranspose2d):\n",
        "        nn.init.xavier_uniform_(module.weight.data)\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSpR39boLUyx"
      },
      "source": [
        "#DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSRxqXT8LR-L",
        "outputId": "6211f751-9486-4750-871e-936d774b9112"
      },
      "source": [
        "############ Unzip data from drive ################################\n",
        "\n",
        "shutil.unpack_archive(config.dir+\"dataset/\"+config.train_file_name+\".zip\",\"\")\n",
        "shutil.unpack_archive(config.dir+\"dataset/\"+config.test_file_name+\".zip\",\"\")\n",
        "shutil.unpack_archive(config.dir+\"dataset/Default.zip\",\"\")\n",
        "train_list=glob.glob(config.train_file_name+'/*')\n",
        "test_list=glob.glob(config.test_file_name+'/*')\n",
        "default_list=glob.glob('Default/*')\n",
        "print(len(train_list),len(test_list),len(default_list))\n",
        "\n",
        "###################################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1548 5 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvceWRYmLYg-"
      },
      "source": [
        "class MRIDataLoader(data.Dataset):\n",
        "\n",
        "    def __init__(self,config,mode='train'):\n",
        "      \n",
        "      self.mode=mode\n",
        "      self.config=config\n",
        "      if self.mode=='train':\n",
        "        self.data_path=config.train_file_name+'/'\n",
        "      \n",
        "      elif self.mode=='test':\n",
        "        self.data_path=config.test_file_name+'/'\n",
        "        self.train_data_path=config.train_file_name+'/'\n",
        "      \n",
        "      if self.mode=='train' or self.mode=='test':\n",
        "        self.img_path_list=glob.glob(self.data_path+'T*')\n",
        "      \n",
        "    def __getitem__(self,index):\n",
        "      if self.mode=='train' or self.mode=='test':\n",
        "        \n",
        "        input_image_index = random.randint(0,len(self.img_path_list)-1)\n",
        "        input_name=self.img_path_list[input_image_index].split('/')[1][:-4]\n",
        "        input_values=input_name.split(',')\n",
        "        input_param_tr = float(input_values[0].split('=')[1])\n",
        "        input_param_te = float(input_values[1].split('=')[1])\n",
        "        input_slice_no = int(input_values[2].split('=')[1])\n",
        "        input_slice_plane = input_values[3].split('=')[1]\n",
        "\n",
        "        output_list = glob.glob(self.data_path+str(input_slice_no)+'/*')\n",
        "        output_image_index = random.randint(0,len(output_list)-1)\n",
        "        output_name = output_list[output_image_index].split('/')[2][:-4]\n",
        "        output_values = output_name.split(',')\n",
        "        output_param_tr = float(output_values[0].split('=')[1])\n",
        "        output_param_te = float(output_values[1].split('=')[1])\n",
        "        output_slice_no = int(output_values[2].split('=')[1])\n",
        "        output_slice_plane = output_values[3].split('=')[1]\n",
        "\n",
        "        input_image=cv2.imread(self.img_path_list[input_image_index],cv2.IMREAD_GRAYSCALE)\n",
        "        output_image=cv2.imread(output_list[output_image_index],cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        input_image=cv2.resize(input_image, (256,256), interpolation=cv2.INTER_LINEAR)\n",
        "        output_image=cv2.resize(output_image, (256,256), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        input_image=input_image.astype(np.float64)\n",
        "        input_image/=255.0\n",
        "        input_image=torch.from_numpy(input_image).unsqueeze(0)\n",
        "        mean=torch.Tensor([0.5])\n",
        "        input_image=input_image-mean.expand_as(input_image)\n",
        "        input_image=input_image*2\n",
        "\n",
        "        output_image=output_image.astype(np.float64)\n",
        "        output_image/=255.0\n",
        "        output_image=torch.from_numpy(output_image).unsqueeze(0)\n",
        "        mean=torch.Tensor([0.5])\n",
        "        output_image=output_image-mean.expand_as(output_image)\n",
        "        output_image=output_image*2\n",
        "\n",
        "        return input_image,output_image,torch.tensor([input_param_te,input_param_tr,output_param_te,output_param_tr]) # input image, ground truth image, parameters of input image and ground truth image\n",
        "      \n",
        "      elif self.mode=='detect':\n",
        "\n",
        "        input_image_path= 'brainweb images/TR=4.5,TE=0.05.jpg'\n",
        "        output_image_path= 'brainweb images/TR=8.0,TE=0.12.jpg' # if output image is not known, give path of a random image and ignore PSNR and MAE in that case\n",
        "        input_param_tr=float(4.5)\n",
        "        input_param_te=float(0.05)\n",
        "        output_param_tr=float(8.0)\n",
        "        output_param_te=float(0.12)\n",
        "\n",
        "        input_image=cv2.imread(input_image_path,cv2.IMREAD_GRAYSCALE)\n",
        "        output_image=cv2.imread(output_image_path,cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        input_image=cv2.resize(input_image, (256,256), interpolation=cv2.INTER_LINEAR)\n",
        "        output_image=cv2.resize(output_image, (256,256), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        input_image=input_image.astype(np.float64)\n",
        "        input_image/=255.0\n",
        "        input_image=torch.from_numpy(input_image).unsqueeze(0)\n",
        "        mean=torch.Tensor([0.5])\n",
        "        input_image=input_image-mean.expand_as(input_image)\n",
        "        input_image=input_image*2\n",
        "\n",
        "        output_image=output_image.astype(np.float64)\n",
        "        output_image/=255.0\n",
        "        output_image=torch.from_numpy(output_image).unsqueeze(0)\n",
        "        mean=torch.Tensor([0.5])\n",
        "        output_image=output_image-mean.expand_as(output_image)\n",
        "        output_image=output_image*2\n",
        "\n",
        "        return input_image,output_image,torch.tensor([input_param_te,input_param_tr,output_param_te,output_param_tr]) # input image, ground truth image, parameters of input image and ground truth image\n",
        "\n",
        "      else:\n",
        "        assert False, \"Unrecognised Mode Detected.\"\n",
        "\n",
        "    def __len__(self):\n",
        "      if self.mode=='detect':\n",
        "        return 1\n",
        "      return len(self.img_path_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1KabdACLcQM"
      },
      "source": [
        "def train_collate(batch):\n",
        "\n",
        "  input_image_list,final_image_list,params_list=[],[],[]\n",
        "  for i,sample in enumerate(batch):\n",
        "    input_image_list.append(sample[0])\n",
        "    final_image_list.append(sample[1])\n",
        "    params_list.append(sample[2])\n",
        "\n",
        "\n",
        "  input_images=torch.stack(input_image_list)\n",
        "  final_images=torch.stack(final_image_list)\n",
        "  params=torch.stack(params_list)\n",
        "\n",
        "  return input_images,final_images,params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dks1WR8_LeMp"
      },
      "source": [
        "def show_image(img): # to display the output image\n",
        "  img=img.cpu().numpy()\n",
        "  img=img/2 + 0.5\n",
        "  img=img.transpose(1,2,0).squeeze(-1)\n",
        "  img*=255.0\n",
        "  print(img.shape)\n",
        "  cv2_imshow(img)\n",
        "\n",
        "def show_diff_image(req_image,gen_image): # shows difference image between generated image and ground truth output\n",
        "  req_image=req_image.cpu().numpy()\n",
        "  req_image=req_image/2 + 0.5\n",
        "  req_image=req_image.transpose(1,2,0).squeeze(-1)\n",
        "  req_image*=255.0\n",
        "\n",
        "  gen_image=gen_image.cpu().numpy()\n",
        "  gen_image=gen_image/2 + 0.5\n",
        "  gen_image=gen_image.transpose(1,2,0).squeeze(-1)\n",
        "  gen_image*=255.0\n",
        "\n",
        "  diff_image=abs(gen_image-req_image)\n",
        "  min_value,max_value,mean_value=np.min(diff_image),np.max(diff_image),np.mean(diff_image)\n",
        "  print(min_value,max_value,mean_value,diff_image.shape)\n",
        "  diff_image=(diff_image-min_value)/(max_value-min_value)\n",
        "  diff_image*=255.0\n",
        "  cv2_imshow(diff_image)\n",
        "  return min_value,max_value,mean_value\n",
        "\n",
        "def save_weights(state,step_no): #deletes previous weight file and saves latest file for param-net model\n",
        "  weight=glob.glob(config.dir+'weights/latest_KParameter*')\n",
        "  assert len(weight)<=1, \"Multiple weights file, delete others.\"\n",
        "  if weight:\n",
        "    open(weight[0], 'w').close()\n",
        "    os.remove(weight[0])\n",
        "  print(\"Saving weights as latest_KParameter_\"+str(step_no))\n",
        "  torch.save(state,config.dir+\"weights/latest_KParameter_\"+str(step_no)+\".pth.tar\")\n",
        "\n",
        "def PSNR_and_SSIM(imageA, imageB): # calculate psnr and ssim between generated image and ground truth output image\n",
        "\n",
        "    # todo: check if code for ssim calculation is correct\n",
        "    \n",
        "    imageA=imageA.cpu().numpy()\n",
        "    imageB=imageB.cpu().numpy()\n",
        "    imageA=imageA.transpose(0,2,3,1)\n",
        "    imageB=imageB.transpose(0,2,3,1)\n",
        "    imageA=imageA/2 + 0.5\n",
        "    imageA*=255.0\n",
        "    imageB=imageB/2 + 0.5\n",
        "    imageB*=255.0\n",
        "    imageA=np.clip(imageA,a_min=0.0,a_max=255.0)\n",
        "    imageB=np.clip(imageB,a_min=0.0,a_max=255.0)\n",
        "\n",
        "    mse = np.mean((imageA - imageB) ** 2)\n",
        "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
        "                  # Therefore PSNR have no importance.\n",
        "        return 100\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
        "    ssim_final=0\n",
        "    for i in range(imageA.shape[0]):\n",
        "      ssim_temp = ssim(imageA[i],imageB[i],multichannel=True)\n",
        "      ssim_final+=ssim_temp\n",
        "    \n",
        "    #ssim_final/=imageA.shape[0]\n",
        "    return psnr,ssim_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSAHUi9rLhcH"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RPRprmqLis2"
      },
      "source": [
        "# initialize autoencoder and param-net\n",
        "end_model=END().to(device)\n",
        "param_model=ParamNet().to(device)\n",
        "\n",
        "param_model.train()\n",
        "end_model.eval()\n",
        "\n",
        "config.mode=\"train\"\n",
        "\n",
        "# initialize dataloader and optimizer\n",
        "dataset=MRIDataLoader(config,config.mode)\n",
        "optimizer_param=optim.Adam(param_model.parameters(),lr=config.lr,betas=(0.5, 0.999))\n",
        "train_loader=DataLoader(dataset,config.batch_size,shuffle=True,collate_fn=train_collate)\n",
        "\n",
        "# check if pre-trained weights exists, initialize accordingly\n",
        "config.param_weight_path=glob.glob(config.dir+'weights/latest_KParameter*')\n",
        "assert len(config.param_weight_path)<=1, \"Multiple weight files detected.\"\n",
        "if len(config.param_weight_path)==1:\n",
        "  config.resume=True\n",
        "  config.param_weight_path=config.param_weight_path[0]\n",
        "else:\n",
        "  config.param_weight_path=None\n",
        "  config.resume=False\n",
        "\n",
        "\n",
        "config.end_weight_path=glob.glob(config.dir+'weights/latest_END*')\n",
        "assert len(config.end_weight_path)<=1, \"Multiple END weight files detected.\"\n",
        "if len(config.end_weight_path)==1:\n",
        "  config.end_weight_path=config.end_weight_path[0]\n",
        "  checkpoint_end=torch.load(config.end_weight_path)\n",
        "  end_model.load_state_dict(checkpoint_end['end_model'])\n",
        "  print(\"END weight file found\",config.end_weight_path)\n",
        "else:\n",
        "  assert False,\"No END weight file found\"\n",
        "\n",
        "# if pre-trained weights for param-net were found previously, load the previous state otherwise initialize weights\n",
        "if config.resume:\n",
        "  checkpoint=torch.load(config.param_weight_path)\n",
        "  param_model.load_state_dict(checkpoint['param_model'])\n",
        "  optimizer_param.load_state_dict(checkpoint['optimizer_param'])\n",
        "  print(\"Resuming training with\",config.param_weight_path)\n",
        "else:\n",
        "  param_model.init_weights()\n",
        "  print(\"No Param weights Found, Weights initilaized\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCrSGE_cMD7U"
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "training=True\n",
        "step=1\n",
        "if config.resume:\n",
        "  step=checkpoint['step']+1\n",
        "L1=nn.L1Loss()\n",
        "MSE=nn.MSELoss()\n",
        "BCE=nn.BCELoss()\n",
        "time_last=time.time()\n",
        "\n",
        "while training:\n",
        "  for i,(input_images,final_images,params) in enumerate(train_loader):\n",
        "\n",
        "    input_images=Variable(input_images.cuda().type(dtype))\n",
        "    final_images=Variable(final_images.cuda().type(dtype))\n",
        "    params=Variable(params.cuda().type(dtype))\n",
        "\n",
        "    # convert parameters to image shape, and stack them together\n",
        "    input_param_te=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,0].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "    input_param_tr=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,1].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "    output_param_te=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,2].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "    output_param_tr=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,3].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "\n",
        "    param_input=torch.zeros(input_images.size(0),512,256,256).cuda().type(dtype)\n",
        "    for j in range(512):\n",
        "      if j%4==0:\n",
        "        param_input[:,j,:,:]=input_param_te.squeeze(1)\n",
        "      elif j%4==1:\n",
        "        param_input[:,j,:,:]=input_param_tr.squeeze(1)\n",
        "      elif j%4==2:\n",
        "        param_input[:,j,:,:]=output_param_te.squeeze(1)\n",
        "      else:\n",
        "        param_input[:,j,:,:]=output_param_tr.squeeze(1)\n",
        "\n",
        "    param_model.zero_grad()\n",
        "\n",
        "    # extract image features of input image from auto-encoder and feed them to param-net along with the parameters\n",
        "    brain_features=end_model(input_images)\n",
        "    \n",
        "    for j,features in enumerate(brain_features):\n",
        "      brain_features[j]=brain_features[j].detach()\n",
        "    param_input=param_input.detach()\n",
        "\n",
        "    out_images=param_model(brain_features,param_input)\n",
        "\n",
        "    loss=MSE(out_images.view(out_images.size(0) ,-1),final_images.view(final_images.size(0),-1))\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_param.step()\n",
        "\n",
        "    this_time=time.time()\n",
        "    if i%10==0:\n",
        "      print(\"Batch No -\",i,\"Completed with time\",this_time-time_last,\".Loss =\",loss.item())\n",
        "    time_last=time.time()\n",
        "  \n",
        "  # save state of model after every epoch\n",
        "  print(\"Epoch \",step,\" done.\")\n",
        "  state={'step':step,\n",
        "         'param_model':param_model.state_dict(),\n",
        "         'optimizer_param':optimizer_param.state_dict()}\n",
        "\n",
        "  if step>7 or step==3:\n",
        "    save_weights(state,step)\n",
        "  with torch.no_grad():\n",
        "        print(\"Input -\")\n",
        "        show_image(input_images[0])\n",
        "        print(\"Required -\")\n",
        "        show_image(final_images[0])\n",
        "        print(\"Generated -\")\n",
        "        show_image(out_images[0])\n",
        "        print(\"Input TE =\",params[0,0],\"Input TR =\",params[0,1],\"Output TE =\",params[0,2],\"Output TR =\",params[0,3])\n",
        "  step+=1\n",
        "  if step==19:\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bigBHTbaMIFN"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_sRhMKRMJBO"
      },
      "source": [
        "# check for latest weights\n",
        "config.param_weight_path=glob.glob(config.dir+'weights/latest_KParameter_16*')\n",
        "assert len(config.param_weight_path)<=1, \"Multiple weight files detected.\"\n",
        "if len(config.param_weight_path)==1:\n",
        "  config.param_weight_path=config.param_weight_path[0]\n",
        "  print(\"Param weight file found\",config.param_weight_path)\n",
        "else:\n",
        "  assert False,\"No Param Weight file found.\"\n",
        "\n",
        "config.end_weight_path=glob.glob(config.dir+'weights/latest_END*')\n",
        "assert len(config.end_weight_path)<=1, \"Multiple END weight files detected.\"\n",
        "if len(config.end_weight_path)==1:\n",
        "  config.end_weight_path=config.end_weight_path[0]\n",
        "  print(\"END weight file found\",config.end_weight_path)\n",
        "else:\n",
        "  assert False,\"No END weight file found\"\n",
        "\n",
        "#initialize models\n",
        "end_model=END().to(device)\n",
        "param_model=ParamNet().to(device)\n",
        "\n",
        "end_model.eval()\n",
        "param_model.eval()\n",
        "\n",
        "#load weights\n",
        "checkpoint_end=torch.load(config.end_weight_path)\n",
        "end_model.load_state_dict(checkpoint_end['end_model'])\n",
        "\n",
        "checkpoint_param=torch.load(config.param_weight_path)\n",
        "param_model.load_state_dict(checkpoint_param['param_model'])\n",
        "final_loss,final_psnr,final_ssim,total_no=0.0,0.0,0.0,0\n",
        "psnr_values=[]\n",
        "min_diffs,max_diffs,mean_diffs,tot1=[],[],[],0\n",
        "\n",
        "MSE=nn.MSELoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  #initialize dataloader\n",
        "  test_data=MRIDataLoader(config,'test')\n",
        "  test_loader=DataLoader(test_data,config.batch_size,shuffle=False,collate_fn=train_collate)\n",
        "  time_last=time.time()\n",
        "  for i,(input_images,final_images,params) in enumerate(test_loader): \n",
        "\n",
        "    input_images=Variable(input_images.cuda().type(dtype))\n",
        "    final_images=Variable(final_images.cuda().type(dtype))\n",
        "    params=Variable(params.cuda().type(dtype))\n",
        "\n",
        "    # convert parameters to image shape, and stack them together\n",
        "    input_param_te=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,0].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "    input_param_tr=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,1].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "    output_param_te=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,2].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "    output_param_tr=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,3].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "\n",
        "    param_input=torch.zeros(input_images.size(0),512,256,256).cuda().type(dtype)\n",
        "    for j in range(512):\n",
        "      if j%4==0:\n",
        "        param_input[:,j,:,:]=input_param_te.squeeze(1)\n",
        "      elif j%4==1:\n",
        "        param_input[:,j,:,:]=input_param_tr.squeeze(1)\n",
        "      elif j%4==2:\n",
        "        param_input[:,j,:,:]=output_param_te.squeeze(1)\n",
        "      else:\n",
        "        param_input[:,j,:,:]=output_param_tr.squeeze(1)\n",
        "\n",
        "    # extract image features of input image from auto-encoder and feed them to param-net along with the parameters\n",
        "    brain_features=end_model(input_images)\n",
        "    \n",
        "    for j,features in enumerate(brain_features):\n",
        "      brain_features[j]=brain_features[j].detach()\n",
        "    param_input=param_input.detach()\n",
        "\n",
        "    out_images=param_model(brain_features,param_input)\n",
        "    loss=MSE(out_images.view(out_images.size(0) ,-1),final_images.view(final_images.size(0),-1))\n",
        "\n",
        "    # calculate psnr and ssim\n",
        "    psnr_temp,ssim_temp=PSNR_and_SSIM(final_images,out_images)\n",
        "    psnr_values.append(psnr_temp)\n",
        "    final_psnr+=psnr_temp\n",
        "    final_ssim+=ssim_temp\n",
        "    final_loss+=loss\n",
        "    total_no+=1\n",
        "\n",
        "    this_time=time.time()\n",
        "    print(\"Batch No -\",i,\"Completed with time\",this_time-time_last,\".Loss =\",loss.item())\n",
        "    time_last=time.time()\n",
        "\n",
        "    # display inputimage, ground truth image, generated image and difference image(|ground truth - generated image|)\n",
        "    if i%10==0:\n",
        "      print(\"Input -\")\n",
        "      show_image(input_images[0])\n",
        "      print(\"Required -\")\n",
        "      show_image(final_images[0])\n",
        "      print(\"Generated -\")\n",
        "      show_image(out_images[0])\n",
        "      print(\"Differnce Image -\")\n",
        "      curr_min,curr_max,curr_mean=show_diff_image(final_images[0],out_images[0])\n",
        "      min_diffs.append(curr_min)\n",
        "      max_diffs.append(curr_max)\n",
        "      mean_diffs.append(curr_mean)\n",
        "      tot1+=1\n",
        "      print(\"Input TE =\",params[0,0],\"Input TR =\",params[0,1])\n",
        "      print(\"Output TE =\",params[0,2],\"Output TR =\",params[0,3])\n",
        "      print(\"Slice No =\",params[0,4])\n",
        "\n",
        "# display average psnr, avg pixel difference\n",
        "final_loss/=total_no\n",
        "final_psnr/=total_no\n",
        "final_ssim/=total_no\n",
        "print(\"Final Loss =\",final_loss,\"Final PSNR =\",final_psnr,\"Final SSIM =\",final_ssim)\n",
        "print(\"PSNR Array =\",psnr_values)\n",
        "avg_min_diff=np.sum(min_diffs)/tot1\n",
        "avg_max_diff=np.sum(max_diffs)/tot1\n",
        "avg_mean_diff=np.sum(mean_diffs)/tot1\n",
        "print(\"Avg Min Difference =\",avg_min_diff,\"Avg Max Difference =\",avg_max_diff,\"Avg Mean Difference =\",avg_mean_diff)\n",
        "\n",
        "# display mean and std dev of pixel differences\n",
        "mean = sum(mean_diffs) / len(mean_diffs)\n",
        "variance = sum([((x - mean) ** 2) for x in mean_diffs]) / len(mean_diffs)\n",
        "res = variance ** 0.5\n",
        "print(\"Mean =\",mean,\"Res =\",res)\n",
        "\n",
        "# display mean and std dev of psnr\n",
        "mean = sum(psnr_values) / len(psnr_values)\n",
        "variance = sum([((x - mean) ** 2) for x in psnr_values]) / len(psnr_values)\n",
        "res = variance ** 0.5\n",
        "print(\"Mean =\",mean,\"Res =\",res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5jv2WEdbf9A"
      },
      "source": [
        "#Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2ef6WrXbfpM"
      },
      "source": [
        "# check for latest weights\n",
        "config.param_weight_path=glob.glob(config.dir+'weights/latest_KParameter_16*')\n",
        "assert len(config.param_weight_path)<=1, \"Multiple weight files detected.\"\n",
        "if len(config.param_weight_path)==1:\n",
        "  config.param_weight_path=config.param_weight_path[0]\n",
        "  print(\"Param weight file found\",config.param_weight_path)\n",
        "else:\n",
        "  assert False,\"No Param Weight file found.\"\n",
        "\n",
        "config.end_weight_path=glob.glob(config.dir+'weights/latest_END*')\n",
        "assert len(config.end_weight_path)<=1, \"Multiple END weight files detected.\"\n",
        "if len(config.end_weight_path)==1:\n",
        "  config.end_weight_path=config.end_weight_path[0]\n",
        "  print(\"END weight file found\",config.end_weight_path)\n",
        "else:\n",
        "  assert False,\"No END weight file found\"\n",
        "\n",
        "#initialize models\n",
        "end_model=END().to(device)\n",
        "param_model=ParamNet().to(device)\n",
        "\n",
        "end_model.eval()\n",
        "param_model.eval()\n",
        "\n",
        "#load weights\n",
        "checkpoint_end=torch.load(config.end_weight_path)\n",
        "end_model.load_state_dict(checkpoint_end['end_model'])\n",
        "\n",
        "checkpoint_param=torch.load(config.param_weight_path)\n",
        "param_model.load_state_dict(checkpoint_param['param_model'])\n",
        "final_loss,final_psnr,final_ssim,total_no=0.0,0.0,0.0,0\n",
        "psnr_values=[]\n",
        "\n",
        "MSE=nn.MSELoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  #initialize dataloader\n",
        "  test_data=MRIDataLoader(config,'detect')\n",
        "  test_loader=DataLoader(test_data,config.batch_size,shuffle=True,collate_fn=train_collate)\n",
        "  time_last=time.time()\n",
        "  for i,(input_images,final_images,params) in enumerate(test_loader):\n",
        "\n",
        "    input_images=Variable(input_images.cuda().type(dtype))\n",
        "    final_images=Variable(final_images.cuda().type(dtype))\n",
        "    params=Variable(params.cuda().type(dtype))\n",
        "\n",
        "    # convert parameters to image shape, and stack them together\n",
        "    input_param_te=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,0].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "    input_param_tr=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,1].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "    output_param_te=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,2].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "    output_param_tr=(torch.zeros(input_images.size(0),1,256,256).cuda()+params[:,3].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)).detach()\n",
        "\n",
        "    param_input=torch.zeros(input_images.size(0),512,256,256).cuda().type(dtype)\n",
        "    for j in range(512):\n",
        "      if j%4==0:\n",
        "        param_input[:,j,:,:]=input_param_te.squeeze(1)\n",
        "      elif j%4==1:\n",
        "        param_input[:,j,:,:]=input_param_tr.squeeze(1)\n",
        "      elif j%4==2:\n",
        "        param_input[:,j,:,:]=output_param_te.squeeze(1)\n",
        "      else:\n",
        "        param_input[:,j,:,:]=output_param_tr.squeeze(1)\n",
        "\n",
        "    # extract image features of input image from auto-encoder and feed them to param-net along with the parameters\n",
        "    brain_features=end_model(input_images)\n",
        "    \n",
        "    for j,features in enumerate(brain_features):\n",
        "      brain_features[j]=brain_features[j].detach()\n",
        "    param_input=param_input.detach()\n",
        "\n",
        "    out_images=param_model(brain_features,param_input)\n",
        "    loss=MSE(out_images.view(out_images.size(0) ,-1),final_images.view(final_images.size(0),-1))\n",
        "\n",
        "    # calculate psnr and ssim\n",
        "    psnr_temp,ssim_temp=PSNR_and_SSIM(final_images,out_images)\n",
        "    psnr_values.append(psnr_temp)\n",
        "    final_psnr+=psnr_temp\n",
        "    final_ssim+=ssim_temp\n",
        "    final_loss+=loss\n",
        "    total_no+=1\n",
        "\n",
        "    this_time=time.time()\n",
        "    print(\"Batch No -\",i,\"Completed with time\",this_time-time_last,\".Loss =\",loss.item())\n",
        "    time_last=time.time()\n",
        "\n",
        "    # display inputimage, ground truth image and generated image\n",
        "    if i%10==0:\n",
        "      print(\"Input -\")\n",
        "      show_image(input_images[0])\n",
        "      print(\"Required -\")\n",
        "      show_image(final_images[0])\n",
        "      print(\"Generated -\")\n",
        "      show_image(out_images[0])\n",
        "      print(\"TE =\",params[0,0],\"TR =\",params[0,1])\n",
        "\n",
        "final_loss/=total_no\n",
        "final_psnr/=total_no\n",
        "final_ssim/=total_no\n",
        "print(\"Final Loss =\",final_loss,\"Final PSNR =\",final_psnr,\"Final SSIM =\",final_ssim)\n",
        "print(\"PSNR Array =\",psnr_values)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}